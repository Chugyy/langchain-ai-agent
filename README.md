# AI Conversational Agent API

Une API REST pour un agent conversationnel IA facilement int√©grable dans des applications tierces.

## Fonctionnalit√©s

- üí¨ Conversation avec un agent IA utilisant LangChain
- üß† Support pour diff√©rents types de m√©moire (buffer, summary)
- üîë Authentification par cl√© API et limitation de d√©bit
- üõ†Ô∏è Sessions configurables avec diff√©rents param√®tres de LLM
- üìä Logging et monitoring complets
- üê≥ Containerisation Docker pour d√©ploiement facile

## Guide de d√©marrage rapide

### Pr√©requis

- Python 3.9 ou sup√©rieur
- Une cl√© API OpenAI

### Installation locale (√©tape par √©tape pour d√©butants)

#### 1. Cloner le d√©p√¥t

```bash
git clone https://github.com/yourusername/ai-agent.git
cd ai-agent
```

#### 2. Cr√©er un environnement virtuel

```bash
# Sur macOS/Linux
python -m venv venv
source venv/bin/activate

# Sur Windows
python -m venv venv
venv\Scripts\activate
```

#### 3. Installer les d√©pendances

```bash
pip install -r requirements.txt
```

#### 4. Configurer les variables d'environnement

Cr√©ez un fichier `.env` √† la racine du projet avec le contenu suivant:

```
# Configuration du LLM
OPENAI_API_KEY=sk-votre-cl√©-api-openai
LLM_NAME=gpt-4o-mini
TEMPERATURE=0.0
MAX_TOKENS=1000

# Configuration de la m√©moire
MEMORY_TYPE=buffer
SESSION_TTL_HOURS=24

# Outils activ√©s (s√©par√©s par des virgules, sans espaces)
ENABLED_TOOLS=shout,file_loader,youtube_transcript

# Configuration du serveur
SERVER_HOST=0.0.0.0
SERVER_PORT=8000
```

> **Important**: Remplacez `sk-votre-cl√©-api-openai` par votre v√©ritable cl√© API OpenAI.

#### 5. D√©marrer le serveur

```bash
# Mode d√©veloppement
python -m app.main

# Ou avec uvicorn directement
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

#### 6. Tester l'API

Vous pouvez maintenant tester l'API avec curl ou un outil comme Postman:

```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer admin-key-for-development" \
  -d '{"message": "Bonjour, comment vas-tu?"}'
```

Le serveur devrait r√©pondre avec quelque chose comme:

```json
{
  "session_id": "550e8400-e29b-41d4-a716-446655440000",
  "reply": "Bonjour! Je suis un assistant IA. Comment puis-je vous aider aujourd'hui?",
  "usage": {
    "prompt_tokens": 25,
    "completion_tokens": 15,
    "total_tokens": 40
  }
}
```

#### 7. Explorer la documentation de l'API

Une fois l'application lanc√©e, visitez `http://localhost:8000/docs` dans votre navigateur pour acc√©der √† la documentation Swagger UI.

### D√©ploiement avec Docker

#### 1. Construire l'image Docker

```bash
docker build -t ai-agent .
```

#### 2. Lancer le conteneur

```bash
docker run -p 8000:8000 --env-file .env ai-agent
```

Alternativement, utilisez docker-compose:

```bash
docker-compose up -d
```

## Tutoriel: Premier projet d'int√©gration

Ce tutoriel vous guide dans la cr√©ation d'une application Python simple qui interagit avec l'API de l'agent IA.

### 1. Cr√©er un nouveau dossier pour votre projet client

```bash
mkdir mon-client-agent-ia
cd mon-client-agent-ia
```

### 2. Cr√©er un environnement virtuel pour ce client

```bash
python -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate sur Windows
```

### 3. Installer les biblioth√®ques n√©cessaires

```bash
pip install requests
```

### 4. Cr√©er un fichier Python pour le client

Cr√©ez un fichier `client.py` avec le contenu suivant:

```python
import requests
import json

# Configuration
API_URL = "http://localhost:8000"
API_KEY = "admin-key-for-development"  # Utilisez votre vraie cl√© API en production

# En-t√™tes pour les requ√™tes
headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {API_KEY}"
}

def chat_with_agent(message, session_id=None):
    """
    Envoie un message √† l'agent et retourne sa r√©ponse.
    
    Args:
        message (str): Le message √† envoyer √† l'agent
        session_id (str, optional): ID de session pour continuer une conversation
        
    Returns:
        dict: R√©ponse compl√®te de l'API
    """
    payload = {"message": message}
    if session_id:
        payload["session_id"] = session_id
        
    response = requests.post(
        f"{API_URL}/chat", 
        headers=headers,
        data=json.dumps(payload)
    )
    
    if response.status_code == 200:
        return response.json()
    else:
        print(f"Erreur: {response.status_code}")
        print(response.text)
        return None

def main():
    print("Client de d√©monstration pour l'Agent IA")
    print("Tapez 'quit' pour quitter")
    
    session_id = None  # Pour stocker l'ID de session
    
    while True:
        user_input = input("\nVous: ")
        if user_input.lower() == 'quit':
            break
            
        result = chat_with_agent(user_input, session_id)
        if result:
            # Extraire et stocker l'ID de session pour la continuit√©
            session_id = result.get("session_id")
            print(f"\nAgent: {result.get('reply')}")
            
            # Afficher des informations sur l'utilisation des tokens (optionnel)
            if "usage" in result:
                usage = result["usage"]
                print(f"\n[Info: {usage.get('total_tokens')} tokens utilis√©s]")

if __name__ == "__main__":
    main()
```

### 5. Ex√©cuter le client

```bash
python client.py
```

Vous pouvez maintenant discuter avec l'agent IA via cette interface en ligne de commande. Le client maintient automatiquement la session de conversation.

### 6. Am√©liorations possibles

- Ajouter une gestion des erreurs plus robuste
- Impl√©menter un m√©canisme de sauvegarde des conversations
- Cr√©er une interface graphique avec Tkinter ou une application web avec Flask/FastAPI

## Documentation de l'API

Les principaux endpoints sont:

- `POST /chat` - Envoyer un message √† l'agent IA
- `GET /sessions/{session_id}` - R√©cup√©rer l'historique d'une session
- `PATCH /sessions/{session_id}/config` - Mettre √† jour la configuration d'une session
- `POST /auth/keys` - G√©n√©rer une nouvelle cl√© API (admin seulement)
- `GET /health` - Endpoint de contr√¥le de sant√©

Pour une documentation compl√®te, consultez les fichiers dans le dossier `/docs` ou l'interface Swagger UI (`/docs`).

## Configuration

La configuration peut √™tre g√©r√©e via des variables d'environnement ou le fichier `.env`.

### Options principales

- `OPENAI_API_KEY` - Votre cl√© API OpenAI
- `LLM_NAME` - Le mod√®le LLM √† utiliser (ex: "gpt-4o-mini")
- `TEMPERATURE` - R√©glage de temp√©rature pour la g√©n√©ration
- `MEMORY_TYPE` - Type de m√©moire √† utiliser ("buffer" ou "summary")
- `SESSION_TTL_HOURS` - Dur√©e de vie des sessions inactives
- `ENABLED_TOOLS` - Liste des outils activ√©s (s√©par√©s par des virgules)
- `ADMIN_API_KEY` - Cl√© API admin pour les op√©rations administratives

## Structure du projet

```
app/
‚îú‚îÄ‚îÄ agents/          # Impl√©mentation de l'agent
‚îú‚îÄ‚îÄ api/             # Endpoints API
‚îú‚îÄ‚îÄ config/          # Configuration
‚îú‚îÄ‚îÄ llm/             # Factory LLM
‚îú‚îÄ‚îÄ memory/          # Gestion de la m√©moire
‚îú‚îÄ‚îÄ tools/           # Outils de l'agent
‚îî‚îÄ‚îÄ utils/           # Utilitaires (settings, logging, etc.)
```

## Tests

Pour ex√©cuter les tests:

```bash
pytest
```

## Licence

Ce projet est sous licence MIT - voir le fichier LICENSE pour plus de d√©tails.